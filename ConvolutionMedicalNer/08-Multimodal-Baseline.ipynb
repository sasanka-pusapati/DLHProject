{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "from gensim.models import Word2Vec, FastText\n",
    "#sasanka2@illinois.edu - commented out unused imports\n",
    "#import glove\n",
    "#from glove import Corpus\n",
    "\n",
    "import collections\n",
    "import gc \n",
    "\n",
    "import keras\n",
    "from keras import backend as K\n",
    "from keras import regularizers\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Flatten, Dense, Dropout, Input, concatenate, Activation, Concatenate, LSTM, GRU\n",
    "from keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D, Conv1D, BatchNormalization, GRU, Convolution1D, LSTM\n",
    "from keras.layers import UpSampling1D, MaxPooling1D, GlobalMaxPooling1D, GlobalAveragePooling1D,MaxPool1D\n",
    "\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, History, ReduceLROnPlateau\n",
    "from keras.utils import np_utils\n",
    "#from keras.backend.tensorflow_backend import set_session, clear_session, get_session\n",
    "from keras.backend import set_session, clear_session, get_session\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "from sklearn.utils import class_weight\n",
    "from sklearn.metrics import average_precision_score, roc_auc_score, accuracy_score, f1_score\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(dict_of_ner):\n",
    "    temp_data = []\n",
    "    for k, v in sorted(dict_of_ner.items()):\n",
    "        temp = []\n",
    "        for embed in v:\n",
    "            temp.append(embed)\n",
    "        temp_data.append(np.mean(temp, axis = 0)) \n",
    "    return np.asarray(temp_data)\n",
    "\n",
    "def make_prediction_multi_avg(model, test_data):\n",
    "    probs = model.predict(test_data)\n",
    "    y_pred = [1 if i>=0.5 else 0 for i in probs]\n",
    "    return probs, y_pred\n",
    "\n",
    "def save_scores_multi_avg(predictions, probs, ground_truth, \n",
    "                          \n",
    "                          embed_name, problem_type, iteration, hidden_unit_size,\n",
    "                          \n",
    "                          sequence_name, type_of_ner):\n",
    "    \n",
    "    auc = roc_auc_score(ground_truth, probs)\n",
    "    auprc = average_precision_score(ground_truth, probs)\n",
    "    acc   = accuracy_score(ground_truth, predictions)\n",
    "    F1    = f1_score(ground_truth, predictions)\n",
    "    \n",
    "    result_dict = {}    \n",
    "    result_dict['auc'] = auc\n",
    "    result_dict['auprc'] = auprc\n",
    "    result_dict['acc'] = acc\n",
    "    result_dict['F1'] = F1\n",
    "    \n",
    "    result_path = \"results/\"\n",
    "    file_name = str(sequence_name)+\"-\"+str(hidden_unit_size)+\"-\"+embed_name\n",
    "    file_name = file_name +\"-\"+problem_type+\"-\"+str(iteration)+\"-\"+type_of_ner+\"-avg-.p\"\n",
    "    pd.to_pickle(result_dict, os.path.join(result_path, file_name))\n",
    "\n",
    "    print(auc, auprc, acc, F1)\n",
    "    \n",
    "def avg_ner_model(layer_name, number_of_unit, embedding_name):\n",
    "\n",
    "    if embedding_name == \"concat\":\n",
    "        input_dimension = 200\n",
    "    else:\n",
    "        input_dimension = 100\n",
    "\n",
    "    sequence_input = Input(shape=(24,104))\n",
    "\n",
    "    input_avg = Input(shape=(input_dimension, ), name = \"avg\")        \n",
    "#     x_1 = Dense(256, activation='relu')(input_avg)\n",
    "#     x_1 = Dropout(0.3)(x_1)\n",
    "    \n",
    "    if layer_name == \"GRU\":\n",
    "        x = GRU(number_of_unit)(sequence_input)\n",
    "    elif layer_name == \"LSTM\":\n",
    "        x = LSTM(number_of_unit)(sequence_input)\n",
    "\n",
    "    x = keras.layers.Concatenate()([x, input_avg])\n",
    "\n",
    "    x = Dense(256, activation='relu')(x)\n",
    "    x = Dropout(0.2)(x)\n",
    "    \n",
    "    # sasanka2@illinois.edu - Using latest api\n",
    "    #logits_regularizer = tf.contrib.layers.l2_regularizer(scale=0.01)\n",
    "    logits_regularizer = tf.keras.regularizers.L2(0.01)\n",
    "    \n",
    "    #preds = Dense(1, activation='sigmoid',use_bias=False,\n",
    "    #                     kernel_initializer=tf.contrib.layers.xavier_initializer(),\n",
    "    #              kernel_regularizer=logits_regularizer)(x)\n",
    "    preds = Dense(1, activation='sigmoid',use_bias=False,\n",
    "                  kernel_initializer=tf.keras.initializers.glorot_normal(),\n",
    "                  kernel_regularizer=logits_regularizer)(x)\n",
    "    \n",
    "    \n",
    "    opt = Adam(lr=0.001, decay = 0.01)\n",
    "    model = Model(inputs=[sequence_input, input_avg], outputs=preds)\n",
    "    model.compile(loss='binary_crossentropy',\n",
    "                  optimizer=opt,\n",
    "                  metrics=['acc'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "type_of_ner = \"new\"\n",
    "\n",
    "x_train_lstm = pd.read_pickle(\"data/\"+type_of_ner+\"_x_train.pkl\")\n",
    "x_dev_lstm = pd.read_pickle(\"data/\"+type_of_ner+\"_x_dev.pkl\")\n",
    "x_test_lstm = pd.read_pickle(\"data/\"+type_of_ner+\"_x_test.pkl\")\n",
    "\n",
    "y_train = pd.read_pickle(\"data/\"+type_of_ner+\"_y_train.pkl\")\n",
    "y_dev = pd.read_pickle(\"data/\"+type_of_ner+\"_y_dev.pkl\")\n",
    "y_test = pd.read_pickle(\"data/\"+type_of_ner+\"_y_test.pkl\")\n",
    "\n",
    "ner_word2vec = pd.read_pickle(\"data/\"+type_of_ner+\"_ner_word2vec_limited_dict.pkl\")\n",
    "ner_fasttext = pd.read_pickle(\"data/\"+type_of_ner+\"_ner_fasttext_limited_dict.pkl\")\n",
    "ner_concat = pd.read_pickle(\"data/\"+type_of_ner+\"_ner_combined_limited_dict.pkl\")\n",
    "\n",
    "train_ids = pd.read_pickle(\"data/\"+type_of_ner+\"_train_ids.pkl\")\n",
    "dev_ids = pd.read_pickle(\"data/\"+type_of_ner+\"_dev_ids.pkl\")\n",
    "test_ids = pd.read_pickle(\"data/\"+type_of_ner+\"_test_ids.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer:  GRU\n",
      "Hidden unit:  128\n",
      "Embedding:  word2vec\n",
      "=============================\n",
      "Iteration number:  1\n",
      "Problem type:  mort_hosp\n",
      "__________________\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/100\n",
      "240/242 [============================>.] - ETA: 0s - loss: 0.2872 - acc: 0.9031\n",
      "Epoch 1: val_loss improved from inf to 0.24518, saving model to avg-word2vec-mort_hosp-best_model.hdf5\n",
      "242/242 [==============================] - 6s 18ms/step - loss: 0.2868 - acc: 0.9032 - val_loss: 0.2452 - val_acc: 0.9161\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - ETA: 0s - loss: 0.2487 - acc: 0.9154\n",
      "Epoch 2: val_loss improved from 0.24518 to 0.23902, saving model to avg-word2vec-mort_hosp-best_model.hdf5\n",
      "242/242 [==============================] - 4s 17ms/step - loss: 0.2487 - acc: 0.9154 - val_loss: 0.2390 - val_acc: 0.9166\n",
      "Epoch 3/100\n",
      "241/242 [============================>.] - ETA: 0s - loss: 0.2358 - acc: 0.9187\n",
      "Epoch 3: val_loss improved from 0.23902 to 0.23457, saving model to avg-word2vec-mort_hosp-best_model.hdf5\n",
      "242/242 [==============================] - 4s 16ms/step - loss: 0.2359 - acc: 0.9186 - val_loss: 0.2346 - val_acc: 0.9197\n",
      "Epoch 4/100\n",
      "241/242 [============================>.] - ETA: 0s - loss: 0.2306 - acc: 0.9184\n",
      "Epoch 4: val_loss improved from 0.23457 to 0.23403, saving model to avg-word2vec-mort_hosp-best_model.hdf5\n",
      "242/242 [==============================] - 4s 18ms/step - loss: 0.2306 - acc: 0.9184 - val_loss: 0.2340 - val_acc: 0.9188\n",
      "Epoch 5/100\n",
      "240/242 [============================>.] - ETA: 0s - loss: 0.2259 - acc: 0.9207\n",
      "Epoch 5: val_loss improved from 0.23403 to 0.23306, saving model to avg-word2vec-mort_hosp-best_model.hdf5\n",
      "242/242 [==============================] - 4s 17ms/step - loss: 0.2262 - acc: 0.9207 - val_loss: 0.2331 - val_acc: 0.9170\n",
      "Epoch 6/100\n",
      "241/242 [============================>.] - ETA: 0s - loss: 0.2217 - acc: 0.9219\n",
      "Epoch 6: val_loss improved from 0.23306 to 0.23238, saving model to avg-word2vec-mort_hosp-best_model.hdf5\n",
      "242/242 [==============================] - 5s 19ms/step - loss: 0.2217 - acc: 0.9219 - val_loss: 0.2324 - val_acc: 0.9152\n",
      "Epoch 7/100\n",
      "241/242 [============================>.] - ETA: 0s - loss: 0.2183 - acc: 0.9236\n",
      "Epoch 7: val_loss improved from 0.23238 to 0.23196, saving model to avg-word2vec-mort_hosp-best_model.hdf5\n",
      "242/242 [==============================] - 4s 17ms/step - loss: 0.2183 - acc: 0.9236 - val_loss: 0.2320 - val_acc: 0.9166\n",
      "Epoch 8/100\n",
      "240/242 [============================>.] - ETA: 0s - loss: 0.2161 - acc: 0.9233\n",
      "Epoch 8: val_loss improved from 0.23196 to 0.23094, saving model to avg-word2vec-mort_hosp-best_model.hdf5\n",
      "242/242 [==============================] - 5s 19ms/step - loss: 0.2161 - acc: 0.9233 - val_loss: 0.2309 - val_acc: 0.9170\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - ETA: 0s - loss: 0.2141 - acc: 0.9240\n",
      "Epoch 9: val_loss improved from 0.23094 to 0.23082, saving model to avg-word2vec-mort_hosp-best_model.hdf5\n",
      "242/242 [==============================] - 5s 19ms/step - loss: 0.2141 - acc: 0.9240 - val_loss: 0.2308 - val_acc: 0.9166\n",
      "Epoch 10/100\n",
      "239/242 [============================>.] - ETA: 0s - loss: 0.2137 - acc: 0.9238\n",
      "Epoch 10: val_loss improved from 0.23082 to 0.23044, saving model to avg-word2vec-mort_hosp-best_model.hdf5\n",
      "242/242 [==============================] - 5s 20ms/step - loss: 0.2132 - acc: 0.9240 - val_loss: 0.2304 - val_acc: 0.9170\n",
      "Epoch 11/100\n",
      "241/242 [============================>.] - ETA: 0s - loss: 0.2118 - acc: 0.9244\n",
      "Epoch 11: val_loss improved from 0.23044 to 0.23036, saving model to avg-word2vec-mort_hosp-best_model.hdf5\n",
      "242/242 [==============================] - 5s 19ms/step - loss: 0.2120 - acc: 0.9242 - val_loss: 0.2304 - val_acc: 0.9143\n",
      "Epoch 12/100\n",
      "240/242 [============================>.] - ETA: 0s - loss: 0.2103 - acc: 0.9253\n",
      "Epoch 12: val_loss did not improve from 0.23036\n",
      "242/242 [==============================] - 5s 19ms/step - loss: 0.2101 - acc: 0.9254 - val_loss: 0.2306 - val_acc: 0.9156\n",
      "Epoch 13/100\n",
      "241/242 [============================>.] - ETA: 0s - loss: 0.2077 - acc: 0.9247\n",
      "Epoch 13: val_loss did not improve from 0.23036\n",
      "242/242 [==============================] - 5s 19ms/step - loss: 0.2080 - acc: 0.9247 - val_loss: 0.2311 - val_acc: 0.9161\n",
      "Epoch 14/100\n",
      "240/242 [============================>.] - ETA: 0s - loss: 0.2066 - acc: 0.9262\n",
      "Epoch 14: val_loss improved from 0.23036 to 0.23021, saving model to avg-word2vec-mort_hosp-best_model.hdf5\n",
      "242/242 [==============================] - 5s 19ms/step - loss: 0.2065 - acc: 0.9262 - val_loss: 0.2302 - val_acc: 0.9161\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - ETA: 0s - loss: 0.2071 - acc: 0.9255\n",
      "Epoch 15: val_loss did not improve from 0.23021\n",
      "242/242 [==============================] - 5s 19ms/step - loss: 0.2071 - acc: 0.9255 - val_loss: 0.2305 - val_acc: 0.9156\n",
      "Epoch 16/100\n",
      "239/242 [============================>.] - ETA: 0s - loss: 0.2060 - acc: 0.9267\n",
      "Epoch 16: val_loss improved from 0.23021 to 0.23018, saving model to avg-word2vec-mort_hosp-best_model.hdf5\n",
      "242/242 [==============================] - 5s 19ms/step - loss: 0.2059 - acc: 0.9268 - val_loss: 0.2302 - val_acc: 0.9170\n",
      "Epoch 17/100\n",
      "240/242 [============================>.] - ETA: 0s - loss: 0.2039 - acc: 0.9250\n",
      "Epoch 17: val_loss improved from 0.23018 to 0.23012, saving model to avg-word2vec-mort_hosp-best_model.hdf5\n",
      "242/242 [==============================] - 5s 20ms/step - loss: 0.2041 - acc: 0.9249 - val_loss: 0.2301 - val_acc: 0.9161\n",
      "Epoch 18/100\n",
      "240/242 [============================>.] - ETA: 0s - loss: 0.2032 - acc: 0.9275\n",
      "Epoch 18: val_loss did not improve from 0.23012\n",
      "242/242 [==============================] - 4s 18ms/step - loss: 0.2029 - acc: 0.9276 - val_loss: 0.2303 - val_acc: 0.9202\n",
      "Epoch 19/100\n",
      "241/242 [============================>.] - ETA: 0s - loss: 0.2032 - acc: 0.9273\n",
      "Epoch 19: val_loss did not improve from 0.23012\n",
      "242/242 [==============================] - 5s 20ms/step - loss: 0.2031 - acc: 0.9273 - val_loss: 0.2302 - val_acc: 0.9170\n",
      "Epoch 20/100\n",
      "239/242 [============================>.] - ETA: 0s - loss: 0.2012 - acc: 0.9279\n",
      "Epoch 20: val_loss improved from 0.23012 to 0.23010, saving model to avg-word2vec-mort_hosp-best_model.hdf5\n",
      "242/242 [==============================] - 4s 18ms/step - loss: 0.2012 - acc: 0.9277 - val_loss: 0.2301 - val_acc: 0.9147\n",
      "Epoch 21/100\n",
      "241/242 [============================>.] - ETA: 0s - loss: 0.2017 - acc: 0.9286\n",
      "Epoch 21: val_loss improved from 0.23010 to 0.23000, saving model to avg-word2vec-mort_hosp-best_model.hdf5\n",
      "242/242 [==============================] - 5s 19ms/step - loss: 0.2016 - acc: 0.9286 - val_loss: 0.2300 - val_acc: 0.9161\n",
      "Epoch 22/100\n",
      "241/242 [============================>.] - ETA: 0s - loss: 0.1998 - acc: 0.9285\n",
      "Epoch 22: val_loss improved from 0.23000 to 0.22996, saving model to avg-word2vec-mort_hosp-best_model.hdf5\n",
      "242/242 [==============================] - 4s 18ms/step - loss: 0.1997 - acc: 0.9286 - val_loss: 0.2300 - val_acc: 0.9166\n",
      "Epoch 23/100\n",
      "240/242 [============================>.] - ETA: 0s - loss: 0.2006 - acc: 0.9293\n",
      "Epoch 23: val_loss improved from 0.22996 to 0.22984, saving model to avg-word2vec-mort_hosp-best_model.hdf5\n",
      "242/242 [==============================] - 5s 19ms/step - loss: 0.2004 - acc: 0.9294 - val_loss: 0.2298 - val_acc: 0.9143\n",
      "Epoch 24/100\n",
      "240/242 [============================>.] - ETA: 0s - loss: 0.1984 - acc: 0.9281\n",
      "Epoch 24: val_loss did not improve from 0.22984\n",
      "242/242 [==============================] - 4s 17ms/step - loss: 0.1981 - acc: 0.9284 - val_loss: 0.2300 - val_acc: 0.9170\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - ETA: 0s - loss: 0.1985 - acc: 0.9282\n",
      "Epoch 25: val_loss did not improve from 0.22984\n",
      "242/242 [==============================] - 5s 19ms/step - loss: 0.1985 - acc: 0.9282 - val_loss: 0.2303 - val_acc: 0.9152\n",
      "Epoch 26/100\n",
      "240/242 [============================>.] - ETA: 0s - loss: 0.1966 - acc: 0.9298\n",
      "Epoch 26: val_loss did not improve from 0.22984\n",
      "242/242 [==============================] - 4s 17ms/step - loss: 0.1971 - acc: 0.9297 - val_loss: 0.2301 - val_acc: 0.9161\n",
      "Epoch 27/100\n",
      "239/242 [============================>.] - ETA: 0s - loss: 0.1961 - acc: 0.9299\n",
      "Epoch 27: val_loss improved from 0.22984 to 0.22975, saving model to avg-word2vec-mort_hosp-best_model.hdf5\n",
      "242/242 [==============================] - 5s 19ms/step - loss: 0.1962 - acc: 0.9297 - val_loss: 0.2297 - val_acc: 0.9161\n",
      "Epoch 28/100\n",
      "240/242 [============================>.] - ETA: 0s - loss: 0.1960 - acc: 0.9296\n",
      "Epoch 28: val_loss improved from 0.22975 to 0.22970, saving model to avg-word2vec-mort_hosp-best_model.hdf5\n",
      "242/242 [==============================] - 4s 17ms/step - loss: 0.1963 - acc: 0.9295 - val_loss: 0.2297 - val_acc: 0.9166\n",
      "Epoch 29/100\n",
      "240/242 [============================>.] - ETA: 0s - loss: 0.1961 - acc: 0.9307\n",
      "Epoch 29: val_loss improved from 0.22970 to 0.22958, saving model to avg-word2vec-mort_hosp-best_model.hdf5\n",
      "242/242 [==============================] - 5s 19ms/step - loss: 0.1962 - acc: 0.9306 - val_loss: 0.2296 - val_acc: 0.9175\n",
      "Epoch 30/100\n",
      "239/242 [============================>.] - ETA: 0s - loss: 0.1960 - acc: 0.9288\n",
      "Epoch 30: val_loss did not improve from 0.22958\n",
      "242/242 [==============================] - 4s 17ms/step - loss: 0.1958 - acc: 0.9289 - val_loss: 0.2300 - val_acc: 0.9152\n",
      "Epoch 31/100\n",
      "239/242 [============================>.] - ETA: 0s - loss: 0.1952 - acc: 0.9290\n",
      "Epoch 31: val_loss improved from 0.22958 to 0.22955, saving model to avg-word2vec-mort_hosp-best_model.hdf5\n",
      "242/242 [==============================] - 5s 19ms/step - loss: 0.1946 - acc: 0.9293 - val_loss: 0.2296 - val_acc: 0.9166\n",
      "Epoch 32/100\n",
      "240/242 [============================>.] - ETA: 0s - loss: 0.1944 - acc: 0.9287\n",
      "Epoch 32: val_loss did not improve from 0.22955\n",
      "242/242 [==============================] - 4s 17ms/step - loss: 0.1941 - acc: 0.9289 - val_loss: 0.2298 - val_acc: 0.9161\n",
      "Epoch 33/100\n",
      "239/242 [============================>.] - ETA: 0s - loss: 0.1942 - acc: 0.9304\n",
      "Epoch 33: val_loss did not improve from 0.22955\n",
      "242/242 [==============================] - 5s 19ms/step - loss: 0.1939 - acc: 0.9306 - val_loss: 0.2299 - val_acc: 0.9161\n",
      "Epoch 34/100\n",
      "241/242 [============================>.] - ETA: 0s - loss: 0.1927 - acc: 0.9304\n",
      "Epoch 34: val_loss did not improve from 0.22955\n",
      "242/242 [==============================] - 4s 18ms/step - loss: 0.1928 - acc: 0.9304 - val_loss: 0.2297 - val_acc: 0.9152\n",
      "Epoch 35/100\n",
      "241/242 [============================>.] - ETA: 0s - loss: 0.1926 - acc: 0.9291\n",
      "Epoch 35: val_loss did not improve from 0.22955\n",
      "242/242 [==============================] - 5s 19ms/step - loss: 0.1925 - acc: 0.9292 - val_loss: 0.2296 - val_acc: 0.9161\n",
      "Epoch 36/100\n",
      "240/242 [============================>.] - ETA: 0s - loss: 0.1935 - acc: 0.9309\n",
      "Epoch 36: val_loss did not improve from 0.22955\n",
      "242/242 [==============================] - 4s 18ms/step - loss: 0.1931 - acc: 0.9310 - val_loss: 0.2297 - val_acc: 0.9152\n",
      "138/138 [==============================] - 1s 5ms/step\n",
      "0.8814059373261597 0.5819727877810379 0.9166856362394719 0.481586402266289\n",
      "Problem type:  mort_icu\n",
      "__________________\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/100\n",
      "241/242 [============================>.] - ETA: 0s - loss: 0.2265 - acc: 0.9340\n",
      "Epoch 1: val_loss improved from inf to 0.17987, saving model to avg-word2vec-mort_icu-best_model.hdf5\n",
      "242/242 [==============================] - 6s 18ms/step - loss: 0.2269 - acc: 0.9339 - val_loss: 0.1799 - val_acc: 0.9430\n",
      "Epoch 2/100\n",
      "241/242 [============================>.] - ETA: 0s - loss: 0.1818 - acc: 0.9428\n",
      "Epoch 2: val_loss improved from 0.17987 to 0.17655, saving model to avg-word2vec-mort_icu-best_model.hdf5\n",
      "242/242 [==============================] - 4s 19ms/step - loss: 0.1819 - acc: 0.9427 - val_loss: 0.1766 - val_acc: 0.9430\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - ETA: 0s - loss: 0.1721 - acc: 0.9457\n",
      "Epoch 3: val_loss improved from 0.17655 to 0.17260, saving model to avg-word2vec-mort_icu-best_model.hdf5\n",
      "242/242 [==============================] - 4s 18ms/step - loss: 0.1721 - acc: 0.9457 - val_loss: 0.1726 - val_acc: 0.9425\n",
      "Epoch 4/100\n",
      "241/242 [============================>.] - ETA: 0s - loss: 0.1659 - acc: 0.9464\n",
      "Epoch 4: val_loss improved from 0.17260 to 0.17254, saving model to avg-word2vec-mort_icu-best_model.hdf5\n",
      "242/242 [==============================] - 5s 20ms/step - loss: 0.1659 - acc: 0.9464 - val_loss: 0.1725 - val_acc: 0.9430\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - ETA: 0s - loss: 0.1637 - acc: 0.9468\n",
      "Epoch 5: val_loss improved from 0.17254 to 0.17193, saving model to avg-word2vec-mort_icu-best_model.hdf5\n",
      "242/242 [==============================] - 4s 18ms/step - loss: 0.1637 - acc: 0.9468 - val_loss: 0.1719 - val_acc: 0.9435\n",
      "Epoch 6/100\n",
      "241/242 [============================>.] - ETA: 0s - loss: 0.1579 - acc: 0.9486\n",
      "Epoch 6: val_loss improved from 0.17193 to 0.17158, saving model to avg-word2vec-mort_icu-best_model.hdf5\n",
      "242/242 [==============================] - 5s 19ms/step - loss: 0.1580 - acc: 0.9486 - val_loss: 0.1716 - val_acc: 0.9439\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - ETA: 0s - loss: 0.1566 - acc: 0.9488\n",
      "Epoch 7: val_loss improved from 0.17158 to 0.17108, saving model to avg-word2vec-mort_icu-best_model.hdf5\n",
      "242/242 [==============================] - 4s 19ms/step - loss: 0.1566 - acc: 0.9488 - val_loss: 0.1711 - val_acc: 0.9425\n",
      "Epoch 8/100\n",
      "239/242 [============================>.] - ETA: 0s - loss: 0.1550 - acc: 0.9498\n",
      "Epoch 8: val_loss improved from 0.17108 to 0.17057, saving model to avg-word2vec-mort_icu-best_model.hdf5\n",
      "242/242 [==============================] - 5s 19ms/step - loss: 0.1547 - acc: 0.9499 - val_loss: 0.1706 - val_acc: 0.9421\n",
      "Epoch 9/100\n",
      "240/242 [============================>.] - ETA: 0s - loss: 0.1515 - acc: 0.9496\n",
      "Epoch 9: val_loss did not improve from 0.17057\n",
      "242/242 [==============================] - 5s 19ms/step - loss: 0.1515 - acc: 0.9495 - val_loss: 0.1711 - val_acc: 0.9421\n",
      "Epoch 10/100\n",
      "239/242 [============================>.] - ETA: 0s - loss: 0.1501 - acc: 0.9510\n",
      "Epoch 10: val_loss did not improve from 0.17057\n",
      "242/242 [==============================] - 4s 19ms/step - loss: 0.1505 - acc: 0.9506 - val_loss: 0.1706 - val_acc: 0.9439\n",
      "Epoch 11/100\n",
      "240/242 [============================>.] - ETA: 0s - loss: 0.1499 - acc: 0.9497\n",
      "Epoch 11: val_loss improved from 0.17057 to 0.17041, saving model to avg-word2vec-mort_icu-best_model.hdf5\n",
      "242/242 [==============================] - 5s 19ms/step - loss: 0.1497 - acc: 0.9499 - val_loss: 0.1704 - val_acc: 0.9448\n",
      "Epoch 12/100\n",
      "239/242 [============================>.] - ETA: 0s - loss: 0.1491 - acc: 0.9516\n",
      "Epoch 12: val_loss did not improve from 0.17041\n",
      "242/242 [==============================] - 4s 18ms/step - loss: 0.1490 - acc: 0.9517 - val_loss: 0.1705 - val_acc: 0.9439\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - ETA: 0s - loss: 0.1480 - acc: 0.9504\n",
      "Epoch 13: val_loss improved from 0.17041 to 0.17030, saving model to avg-word2vec-mort_icu-best_model.hdf5\n",
      "242/242 [==============================] - 5s 19ms/step - loss: 0.1480 - acc: 0.9504 - val_loss: 0.1703 - val_acc: 0.9430\n",
      "Epoch 14/100\n",
      "240/242 [============================>.] - ETA: 0s - loss: 0.1456 - acc: 0.9516\n",
      "Epoch 14: val_loss did not improve from 0.17030\n",
      "242/242 [==============================] - 5s 19ms/step - loss: 0.1457 - acc: 0.9515 - val_loss: 0.1706 - val_acc: 0.9439\n",
      "Epoch 15/100\n",
      "240/242 [============================>.] - ETA: 0s - loss: 0.1441 - acc: 0.9528\n",
      "Epoch 15: val_loss improved from 0.17030 to 0.17029, saving model to avg-word2vec-mort_icu-best_model.hdf5\n",
      "242/242 [==============================] - 5s 20ms/step - loss: 0.1440 - acc: 0.9528 - val_loss: 0.1703 - val_acc: 0.9435\n",
      "Epoch 16/100\n",
      "241/242 [============================>.] - ETA: 0s - loss: 0.1445 - acc: 0.9520\n",
      "Epoch 16: val_loss did not improve from 0.17029\n",
      "242/242 [==============================] - 5s 19ms/step - loss: 0.1445 - acc: 0.9519 - val_loss: 0.1704 - val_acc: 0.9448\n",
      "Epoch 17/100\n",
      "241/242 [============================>.] - ETA: 0s - loss: 0.1430 - acc: 0.9528\n",
      "Epoch 17: val_loss did not improve from 0.17029\n",
      "242/242 [==============================] - 5s 20ms/step - loss: 0.1429 - acc: 0.9528 - val_loss: 0.1707 - val_acc: 0.9439\n",
      "Epoch 18/100\n",
      "241/242 [============================>.] - ETA: 0s - loss: 0.1410 - acc: 0.9536\n",
      "Epoch 18: val_loss did not improve from 0.17029\n",
      "242/242 [==============================] - 5s 19ms/step - loss: 0.1412 - acc: 0.9535 - val_loss: 0.1706 - val_acc: 0.9453\n",
      "Epoch 19/100\n",
      "241/242 [============================>.] - ETA: 0s - loss: 0.1421 - acc: 0.9520\n",
      "Epoch 19: val_loss did not improve from 0.17029\n",
      "242/242 [==============================] - 5s 19ms/step - loss: 0.1421 - acc: 0.9520 - val_loss: 0.1704 - val_acc: 0.9448\n",
      "Epoch 20/100\n",
      "239/242 [============================>.] - ETA: 0s - loss: 0.1408 - acc: 0.9527\n",
      "Epoch 20: val_loss did not improve from 0.17029\n",
      "242/242 [==============================] - 4s 19ms/step - loss: 0.1411 - acc: 0.9525 - val_loss: 0.1705 - val_acc: 0.9444\n",
      "138/138 [==============================] - 1s 4ms/step\n",
      "0.891799382576284 0.5272383235591925 0.941042567721375 0.4332603938730853\n",
      "Embedding:  fasttext\n",
      "=============================\n",
      "Iteration number:  1\n",
      "Problem type:  mort_hosp\n",
      "__________________\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/100\n",
      "239/242 [============================>.] - ETA: 0s - loss: 0.2966 - acc: 0.9027\n",
      "Epoch 1: val_loss improved from inf to 0.25116, saving model to avg-fasttext-mort_hosp-best_model.hdf5\n",
      "242/242 [==============================] - 6s 18ms/step - loss: 0.2964 - acc: 0.9027 - val_loss: 0.2512 - val_acc: 0.9143\n",
      "Epoch 2/100\n",
      "241/242 [============================>.] - ETA: 0s - loss: 0.2528 - acc: 0.9132\n",
      "Epoch 2: val_loss improved from 0.25116 to 0.24342, saving model to avg-fasttext-mort_hosp-best_model.hdf5\n",
      "242/242 [==============================] - 5s 19ms/step - loss: 0.2528 - acc: 0.9132 - val_loss: 0.2434 - val_acc: 0.9166\n",
      "Epoch 3/100\n",
      "240/242 [============================>.] - ETA: 0s - loss: 0.2410 - acc: 0.9165\n",
      "Epoch 3: val_loss improved from 0.24342 to 0.24044, saving model to avg-fasttext-mort_hosp-best_model.hdf5\n",
      "242/242 [==============================] - 5s 19ms/step - loss: 0.2412 - acc: 0.9163 - val_loss: 0.2404 - val_acc: 0.9170\n",
      "Epoch 4/100\n",
      "241/242 [============================>.] - ETA: 0s - loss: 0.2319 - acc: 0.9202\n",
      "Epoch 4: val_loss improved from 0.24044 to 0.23925, saving model to avg-fasttext-mort_hosp-best_model.hdf5\n",
      "242/242 [==============================] - 5s 20ms/step - loss: 0.2319 - acc: 0.9201 - val_loss: 0.2393 - val_acc: 0.9179\n",
      "Epoch 5/100\n",
      "240/242 [============================>.] - ETA: 0s - loss: 0.2271 - acc: 0.9207\n",
      "Epoch 5: val_loss improved from 0.23925 to 0.23874, saving model to avg-fasttext-mort_hosp-best_model.hdf5\n",
      "242/242 [==============================] - 5s 19ms/step - loss: 0.2269 - acc: 0.9207 - val_loss: 0.2387 - val_acc: 0.9184\n",
      "Epoch 6/100\n",
      "239/242 [============================>.] - ETA: 0s - loss: 0.2234 - acc: 0.9227\n",
      "Epoch 6: val_loss improved from 0.23874 to 0.23603, saving model to avg-fasttext-mort_hosp-best_model.hdf5\n",
      "242/242 [==============================] - 5s 19ms/step - loss: 0.2232 - acc: 0.9229 - val_loss: 0.2360 - val_acc: 0.9188\n",
      "Epoch 7/100\n",
      "240/242 [============================>.] - ETA: 0s - loss: 0.2189 - acc: 0.9242\n",
      "Epoch 7: val_loss did not improve from 0.23603\n",
      "242/242 [==============================] - 5s 19ms/step - loss: 0.2190 - acc: 0.9242 - val_loss: 0.2365 - val_acc: 0.9193\n",
      "Epoch 8/100\n",
      "241/242 [============================>.] - ETA: 0s - loss: 0.2174 - acc: 0.9245\n",
      "Epoch 8: val_loss improved from 0.23603 to 0.23563, saving model to avg-fasttext-mort_hosp-best_model.hdf5\n",
      "242/242 [==============================] - 5s 19ms/step - loss: 0.2174 - acc: 0.9245 - val_loss: 0.2356 - val_acc: 0.9184\n",
      "Epoch 9/100\n",
      "241/242 [============================>.] - ETA: 0s - loss: 0.2158 - acc: 0.9252\n",
      "Epoch 9: val_loss improved from 0.23563 to 0.23534, saving model to avg-fasttext-mort_hosp-best_model.hdf5\n",
      "242/242 [==============================] - 5s 19ms/step - loss: 0.2157 - acc: 0.9253 - val_loss: 0.2353 - val_acc: 0.9188\n",
      "Epoch 10/100\n",
      "239/242 [============================>.] - ETA: 0s - loss: 0.2136 - acc: 0.9249\n",
      "Epoch 10: val_loss improved from 0.23534 to 0.23526, saving model to avg-fasttext-mort_hosp-best_model.hdf5\n",
      "242/242 [==============================] - 5s 19ms/step - loss: 0.2130 - acc: 0.9254 - val_loss: 0.2353 - val_acc: 0.9175\n",
      "Epoch 11/100\n",
      "240/242 [============================>.] - ETA: 0s - loss: 0.2125 - acc: 0.9260\n",
      "Epoch 11: val_loss did not improve from 0.23526\n",
      "242/242 [==============================] - 5s 20ms/step - loss: 0.2122 - acc: 0.9264 - val_loss: 0.2355 - val_acc: 0.9161\n",
      "Epoch 12/100\n",
      "239/242 [============================>.] - ETA: 0s - loss: 0.2107 - acc: 0.9265\n",
      "Epoch 12: val_loss improved from 0.23526 to 0.23450, saving model to avg-fasttext-mort_hosp-best_model.hdf5\n",
      "242/242 [==============================] - 5s 19ms/step - loss: 0.2107 - acc: 0.9263 - val_loss: 0.2345 - val_acc: 0.9166\n",
      "Epoch 13/100\n",
      "241/242 [============================>.] - ETA: 0s - loss: 0.2081 - acc: 0.9263\n",
      "Epoch 13: val_loss did not improve from 0.23450\n",
      "242/242 [==============================] - 5s 20ms/step - loss: 0.2080 - acc: 0.9264 - val_loss: 0.2347 - val_acc: 0.9156\n",
      "Epoch 14/100\n",
      "241/242 [============================>.] - ETA: 0s - loss: 0.2073 - acc: 0.9275\n",
      "Epoch 14: val_loss improved from 0.23450 to 0.23392, saving model to avg-fasttext-mort_hosp-best_model.hdf5\n",
      "242/242 [==============================] - 5s 19ms/step - loss: 0.2073 - acc: 0.9275 - val_loss: 0.2339 - val_acc: 0.9170\n",
      "Epoch 15/100\n",
      "240/242 [============================>.] - ETA: 0s - loss: 0.2055 - acc: 0.9266\n",
      "Epoch 15: val_loss did not improve from 0.23392\n",
      "242/242 [==============================] - 5s 21ms/step - loss: 0.2060 - acc: 0.9266 - val_loss: 0.2346 - val_acc: 0.9188\n",
      "Epoch 16/100\n",
      "241/242 [============================>.] - ETA: 0s - loss: 0.2061 - acc: 0.9284\n",
      "Epoch 16: val_loss did not improve from 0.23392\n",
      "242/242 [==============================] - 5s 19ms/step - loss: 0.2061 - acc: 0.9284 - val_loss: 0.2342 - val_acc: 0.9143\n",
      "Epoch 17/100\n",
      "241/242 [============================>.] - ETA: 0s - loss: 0.2042 - acc: 0.9276\n",
      "Epoch 17: val_loss improved from 0.23392 to 0.23346, saving model to avg-fasttext-mort_hosp-best_model.hdf5\n",
      "242/242 [==============================] - 5s 21ms/step - loss: 0.2041 - acc: 0.9277 - val_loss: 0.2335 - val_acc: 0.9197\n",
      "Epoch 18/100\n",
      "241/242 [============================>.] - ETA: 0s - loss: 0.2039 - acc: 0.9280\n",
      "Epoch 18: val_loss did not improve from 0.23346\n",
      "242/242 [==============================] - 5s 19ms/step - loss: 0.2038 - acc: 0.9281 - val_loss: 0.2337 - val_acc: 0.9175\n",
      "Epoch 19/100\n",
      "241/242 [============================>.] - ETA: 0s - loss: 0.2027 - acc: 0.9282\n",
      "Epoch 19: val_loss did not improve from 0.23346\n",
      "242/242 [==============================] - 5s 20ms/step - loss: 0.2026 - acc: 0.9282 - val_loss: 0.2336 - val_acc: 0.9175\n",
      "Epoch 20/100\n",
      "240/242 [============================>.] - ETA: 0s - loss: 0.2010 - acc: 0.9288\n",
      "Epoch 20: val_loss improved from 0.23346 to 0.23331, saving model to avg-fasttext-mort_hosp-best_model.hdf5\n",
      "242/242 [==============================] - 5s 19ms/step - loss: 0.2010 - acc: 0.9289 - val_loss: 0.2333 - val_acc: 0.9170\n",
      "Epoch 21/100\n",
      "241/242 [============================>.] - ETA: 0s - loss: 0.2019 - acc: 0.9286\n",
      "Epoch 21: val_loss improved from 0.23331 to 0.23326, saving model to avg-fasttext-mort_hosp-best_model.hdf5\n",
      "242/242 [==============================] - 5s 19ms/step - loss: 0.2018 - acc: 0.9286 - val_loss: 0.2333 - val_acc: 0.9179\n",
      "Epoch 22/100\n",
      "240/242 [============================>.] - ETA: 0s - loss: 0.2005 - acc: 0.9286\n",
      "Epoch 22: val_loss did not improve from 0.23326\n",
      "242/242 [==============================] - 5s 19ms/step - loss: 0.2003 - acc: 0.9288 - val_loss: 0.2337 - val_acc: 0.9161\n",
      "Epoch 23/100\n",
      "241/242 [============================>.] - ETA: 0s - loss: 0.2010 - acc: 0.9286\n",
      "Epoch 23: val_loss improved from 0.23326 to 0.23319, saving model to avg-fasttext-mort_hosp-best_model.hdf5\n",
      "242/242 [==============================] - 5s 19ms/step - loss: 0.2008 - acc: 0.9286 - val_loss: 0.2332 - val_acc: 0.9170\n",
      "Epoch 24/100\n",
      "240/242 [============================>.] - ETA: 0s - loss: 0.2003 - acc: 0.9306\n",
      "Epoch 24: val_loss improved from 0.23319 to 0.23297, saving model to avg-fasttext-mort_hosp-best_model.hdf5\n",
      "242/242 [==============================] - 5s 19ms/step - loss: 0.2000 - acc: 0.9308 - val_loss: 0.2330 - val_acc: 0.9179\n",
      "Epoch 25/100\n",
      "240/242 [============================>.] - ETA: 0s - loss: 0.1989 - acc: 0.9283\n",
      "Epoch 25: val_loss did not improve from 0.23297\n",
      "242/242 [==============================] - 5s 19ms/step - loss: 0.1989 - acc: 0.9284 - val_loss: 0.2333 - val_acc: 0.9161\n",
      "Epoch 26/100\n",
      "241/242 [============================>.] - ETA: 0s - loss: 0.1972 - acc: 0.9314\n",
      "Epoch 26: val_loss did not improve from 0.23297\n",
      "242/242 [==============================] - 5s 19ms/step - loss: 0.1973 - acc: 0.9314 - val_loss: 0.2333 - val_acc: 0.9179\n",
      "Epoch 27/100\n",
      "239/242 [============================>.] - ETA: 0s - loss: 0.1976 - acc: 0.9298\n",
      "Epoch 27: val_loss did not improve from 0.23297\n",
      "242/242 [==============================] - 4s 19ms/step - loss: 0.1981 - acc: 0.9296 - val_loss: 0.2334 - val_acc: 0.9156\n",
      "Epoch 28/100\n",
      "240/242 [============================>.] - ETA: 0s - loss: 0.1976 - acc: 0.9305\n",
      "Epoch 28: val_loss did not improve from 0.23297\n",
      "242/242 [==============================] - 5s 19ms/step - loss: 0.1974 - acc: 0.9306 - val_loss: 0.2334 - val_acc: 0.9175\n",
      "Epoch 29/100\n",
      "239/242 [============================>.] - ETA: 0s - loss: 0.1966 - acc: 0.9311\n",
      "Epoch 29: val_loss did not improve from 0.23297\n",
      "242/242 [==============================] - 5s 19ms/step - loss: 0.1967 - acc: 0.9311 - val_loss: 0.2333 - val_acc: 0.9161\n",
      "138/138 [==============================] - 1s 4ms/step\n",
      "0.8822491150186176 0.5828216467478863 0.9180514454814478 0.4857142857142857\n",
      "Problem type:  mort_icu\n",
      "__________________\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/100\n",
      "239/242 [============================>.] - ETA: 0s - loss: 0.2277 - acc: 0.9321\n",
      "Epoch 1: val_loss improved from inf to 0.18287, saving model to avg-fasttext-mort_icu-best_model.hdf5\n",
      "242/242 [==============================] - 6s 18ms/step - loss: 0.2279 - acc: 0.9318 - val_loss: 0.1829 - val_acc: 0.9412\n",
      "Epoch 2/100\n",
      "241/242 [============================>.] - ETA: 0s - loss: 0.1872 - acc: 0.9406\n",
      "Epoch 2: val_loss improved from 0.18287 to 0.17811, saving model to avg-fasttext-mort_icu-best_model.hdf5\n",
      "242/242 [==============================] - 5s 19ms/step - loss: 0.1872 - acc: 0.9406 - val_loss: 0.1781 - val_acc: 0.9407\n",
      "Epoch 3/100\n",
      "241/242 [============================>.] - ETA: 0s - loss: 0.1768 - acc: 0.9440\n",
      "Epoch 3: val_loss improved from 0.17811 to 0.17509, saving model to avg-fasttext-mort_icu-best_model.hdf5\n",
      "242/242 [==============================] - 5s 20ms/step - loss: 0.1767 - acc: 0.9440 - val_loss: 0.1751 - val_acc: 0.9421\n",
      "Epoch 4/100\n",
      "241/242 [============================>.] - ETA: 0s - loss: 0.1710 - acc: 0.9446\n",
      "Epoch 4: val_loss improved from 0.17509 to 0.17292, saving model to avg-fasttext-mort_icu-best_model.hdf5\n",
      "242/242 [==============================] - 5s 21ms/step - loss: 0.1709 - acc: 0.9446 - val_loss: 0.1729 - val_acc: 0.9416\n",
      "Epoch 5/100\n",
      "239/242 [============================>.] - ETA: 0s - loss: 0.1664 - acc: 0.9447\n",
      "Epoch 5: val_loss improved from 0.17292 to 0.17260, saving model to avg-fasttext-mort_icu-best_model.hdf5\n",
      "242/242 [==============================] - 5s 19ms/step - loss: 0.1662 - acc: 0.9449 - val_loss: 0.1726 - val_acc: 0.9430\n",
      "Epoch 6/100\n",
      "241/242 [============================>.] - ETA: 0s - loss: 0.1632 - acc: 0.9471\n",
      "Epoch 6: val_loss improved from 0.17260 to 0.17216, saving model to avg-fasttext-mort_icu-best_model.hdf5\n",
      "242/242 [==============================] - 5s 21ms/step - loss: 0.1631 - acc: 0.9471 - val_loss: 0.1722 - val_acc: 0.9435\n",
      "Epoch 7/100\n",
      "239/242 [============================>.] - ETA: 0s - loss: 0.1599 - acc: 0.9463\n",
      "Epoch 7: val_loss improved from 0.17216 to 0.17112, saving model to avg-fasttext-mort_icu-best_model.hdf5\n",
      "242/242 [==============================] - 4s 18ms/step - loss: 0.1600 - acc: 0.9465 - val_loss: 0.1711 - val_acc: 0.9435\n",
      "Epoch 8/100\n",
      "239/242 [============================>.] - ETA: 0s - loss: 0.1565 - acc: 0.9489\n",
      "Epoch 8: val_loss improved from 0.17112 to 0.17098, saving model to avg-fasttext-mort_icu-best_model.hdf5\n",
      "242/242 [==============================] - 5s 20ms/step - loss: 0.1567 - acc: 0.9488 - val_loss: 0.1710 - val_acc: 0.9435\n",
      "Epoch 9/100\n",
      "240/242 [============================>.] - ETA: 0s - loss: 0.1538 - acc: 0.9492\n",
      "Epoch 9: val_loss improved from 0.17098 to 0.17033, saving model to avg-fasttext-mort_icu-best_model.hdf5\n",
      "242/242 [==============================] - 5s 19ms/step - loss: 0.1544 - acc: 0.9491 - val_loss: 0.1703 - val_acc: 0.9425\n",
      "Epoch 10/100\n",
      "239/242 [============================>.] - ETA: 0s - loss: 0.1546 - acc: 0.9495\n",
      "Epoch 10: val_loss did not improve from 0.17033\n",
      "242/242 [==============================] - 5s 20ms/step - loss: 0.1544 - acc: 0.9495 - val_loss: 0.1706 - val_acc: 0.9435\n",
      "Epoch 11/100\n",
      "241/242 [============================>.] - ETA: 0s - loss: 0.1524 - acc: 0.9500\n",
      "Epoch 11: val_loss improved from 0.17033 to 0.17007, saving model to avg-fasttext-mort_icu-best_model.hdf5\n",
      "242/242 [==============================] - 5s 19ms/step - loss: 0.1525 - acc: 0.9499 - val_loss: 0.1701 - val_acc: 0.9430\n",
      "Epoch 12/100\n",
      "241/242 [============================>.] - ETA: 0s - loss: 0.1507 - acc: 0.9509\n",
      "Epoch 12: val_loss improved from 0.17007 to 0.17000, saving model to avg-fasttext-mort_icu-best_model.hdf5\n",
      "242/242 [==============================] - 5s 19ms/step - loss: 0.1506 - acc: 0.9510 - val_loss: 0.1700 - val_acc: 0.9430\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - ETA: 0s - loss: 0.1496 - acc: 0.9516\n",
      "Epoch 13: val_loss did not improve from 0.17000\n",
      "242/242 [==============================] - 5s 19ms/step - loss: 0.1496 - acc: 0.9516 - val_loss: 0.1702 - val_acc: 0.9439\n",
      "Epoch 14/100\n",
      "240/242 [============================>.] - ETA: 0s - loss: 0.1481 - acc: 0.9518\n",
      "Epoch 14: val_loss did not improve from 0.17000\n",
      "242/242 [==============================] - 5s 19ms/step - loss: 0.1485 - acc: 0.9516 - val_loss: 0.1701 - val_acc: 0.9435\n",
      "Epoch 15/100\n",
      "240/242 [============================>.] - ETA: 0s - loss: 0.1463 - acc: 0.9512\n",
      "Epoch 15: val_loss did not improve from 0.17000\n",
      "242/242 [==============================] - 5s 19ms/step - loss: 0.1464 - acc: 0.9512 - val_loss: 0.1700 - val_acc: 0.9435\n",
      "Epoch 16/100\n",
      "239/242 [============================>.] - ETA: 0s - loss: 0.1470 - acc: 0.9515\n",
      "Epoch 16: val_loss did not improve from 0.17000\n",
      "242/242 [==============================] - 5s 19ms/step - loss: 0.1469 - acc: 0.9516 - val_loss: 0.1702 - val_acc: 0.9439\n",
      "Epoch 17/100\n",
      "240/242 [============================>.] - ETA: 0s - loss: 0.1458 - acc: 0.9516\n",
      "Epoch 17: val_loss did not improve from 0.17000\n",
      "242/242 [==============================] - 5s 20ms/step - loss: 0.1455 - acc: 0.9516 - val_loss: 0.1701 - val_acc: 0.9439\n",
      "138/138 [==============================] - 1s 4ms/step\n",
      "0.8896577623777527 0.5295193151047947 0.9417254723423628 0.452991452991453\n",
      "Hidden unit:  256\n",
      "Embedding:  word2vec\n",
      "=============================\n",
      "Iteration number:  1\n",
      "Problem type:  mort_hosp\n",
      "__________________\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - ETA: 0s - loss: 0.2851 - acc: 0.9024\n",
      "Epoch 1: val_loss improved from inf to 0.24235, saving model to avg-word2vec-mort_hosp-best_model.hdf5\n",
      "242/242 [==============================] - 12s 45ms/step - loss: 0.2851 - acc: 0.9024 - val_loss: 0.2424 - val_acc: 0.9170\n",
      "Epoch 2/100\n",
      "241/242 [============================>.] - ETA: 0s - loss: 0.2396 - acc: 0.9174\n",
      "Epoch 2: val_loss improved from 0.24235 to 0.23638, saving model to avg-word2vec-mort_hosp-best_model.hdf5\n",
      "242/242 [==============================] - 10s 43ms/step - loss: 0.2398 - acc: 0.9174 - val_loss: 0.2364 - val_acc: 0.9143\n",
      "Epoch 3/100\n",
      "241/242 [============================>.] - ETA: 0s - loss: 0.2273 - acc: 0.9199\n",
      "Epoch 3: val_loss did not improve from 0.23638\n",
      "242/242 [==============================] - 10s 43ms/step - loss: 0.2271 - acc: 0.9200 - val_loss: 0.2370 - val_acc: 0.9147\n",
      "Epoch 4/100\n",
      "241/242 [============================>.] - ETA: 0s - loss: 0.2212 - acc: 0.9215\n",
      "Epoch 4: val_loss did not improve from 0.23638\n",
      "242/242 [==============================] - 10s 43ms/step - loss: 0.2210 - acc: 0.9216 - val_loss: 0.2376 - val_acc: 0.9138\n",
      "Epoch 5/100\n",
      "241/242 [============================>.] - ETA: 0s - loss: 0.2144 - acc: 0.9241\n",
      "Epoch 5: val_loss did not improve from 0.23638\n",
      "242/242 [==============================] - 10s 43ms/step - loss: 0.2146 - acc: 0.9240 - val_loss: 0.2377 - val_acc: 0.9124\n",
      "Epoch 6/100\n",
      "241/242 [============================>.] - ETA: 0s - loss: 0.2098 - acc: 0.9264\n",
      "Epoch 6: val_loss improved from 0.23638 to 0.23606, saving model to avg-word2vec-mort_hosp-best_model.hdf5\n",
      "242/242 [==============================] - 10s 43ms/step - loss: 0.2097 - acc: 0.9265 - val_loss: 0.2361 - val_acc: 0.9152\n",
      "Epoch 7/100\n",
      "241/242 [============================>.] - ETA: 0s - loss: 0.2079 - acc: 0.9267\n",
      "Epoch 7: val_loss improved from 0.23606 to 0.23584, saving model to avg-word2vec-mort_hosp-best_model.hdf5\n",
      "242/242 [==============================] - 11s 44ms/step - loss: 0.2080 - acc: 0.9267 - val_loss: 0.2358 - val_acc: 0.9134\n",
      "Epoch 8/100\n",
      "241/242 [============================>.] - ETA: 0s - loss: 0.2045 - acc: 0.9286\n",
      "Epoch 8: val_loss did not improve from 0.23584\n",
      "242/242 [==============================] - 11s 46ms/step - loss: 0.2045 - acc: 0.9286 - val_loss: 0.2361 - val_acc: 0.9143\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - ETA: 0s - loss: 0.2023 - acc: 0.9282\n",
      "Epoch 9: val_loss improved from 0.23584 to 0.23488, saving model to avg-word2vec-mort_hosp-best_model.hdf5\n",
      "242/242 [==============================] - 10s 43ms/step - loss: 0.2023 - acc: 0.9282 - val_loss: 0.2349 - val_acc: 0.9147\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - ETA: 0s - loss: 0.1999 - acc: 0.9295\n",
      "Epoch 10: val_loss did not improve from 0.23488\n",
      "242/242 [==============================] - 10s 42ms/step - loss: 0.1999 - acc: 0.9295 - val_loss: 0.2356 - val_acc: 0.9134\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - ETA: 0s - loss: 0.1975 - acc: 0.9304\n",
      "Epoch 11: val_loss did not improve from 0.23488\n",
      "242/242 [==============================] - 10s 43ms/step - loss: 0.1975 - acc: 0.9304 - val_loss: 0.2375 - val_acc: 0.9111\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - ETA: 0s - loss: 0.1953 - acc: 0.9307\n",
      "Epoch 12: val_loss did not improve from 0.23488\n",
      "242/242 [==============================] - 12s 50ms/step - loss: 0.1953 - acc: 0.9307 - val_loss: 0.2368 - val_acc: 0.9147\n",
      "Epoch 13/100\n",
      "241/242 [============================>.] - ETA: 0s - loss: 0.1934 - acc: 0.9315\n",
      "Epoch 13: val_loss did not improve from 0.23488\n",
      "242/242 [==============================] - 11s 46ms/step - loss: 0.1936 - acc: 0.9314 - val_loss: 0.2362 - val_acc: 0.9120\n",
      "Epoch 14/100\n",
      "241/242 [============================>.] - ETA: 0s - loss: 0.1925 - acc: 0.9326\n",
      "Epoch 14: val_loss did not improve from 0.23488\n",
      "242/242 [==============================] - 12s 48ms/step - loss: 0.1925 - acc: 0.9326 - val_loss: 0.2374 - val_acc: 0.9129\n",
      "138/138 [==============================] - 2s 10ms/step\n",
      "0.8823004816440818 0.5809501332338837 0.9169132711131346 0.46559297218155193\n",
      "Problem type:  mort_icu\n",
      "__________________\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - ETA: 0s - loss: 0.2114 - acc: 0.9368\n",
      "Epoch 1: val_loss improved from inf to 0.17474, saving model to avg-word2vec-mort_icu-best_model.hdf5\n",
      "242/242 [==============================] - 15s 54ms/step - loss: 0.2114 - acc: 0.9368 - val_loss: 0.1747 - val_acc: 0.9439\n",
      "Epoch 2/100\n",
      "241/242 [============================>.] - ETA: 0s - loss: 0.1751 - acc: 0.9449\n",
      "Epoch 2: val_loss improved from 0.17474 to 0.16895, saving model to avg-word2vec-mort_icu-best_model.hdf5\n",
      "242/242 [==============================] - 13s 54ms/step - loss: 0.1753 - acc: 0.9449 - val_loss: 0.1690 - val_acc: 0.9453\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - ETA: 0s - loss: 0.1642 - acc: 0.9483\n",
      "Epoch 3: val_loss did not improve from 0.16895\n",
      "242/242 [==============================] - 12s 51ms/step - loss: 0.1642 - acc: 0.9483 - val_loss: 0.1697 - val_acc: 0.9430\n",
      "Epoch 4/100\n",
      "241/242 [============================>.] - ETA: 0s - loss: 0.1573 - acc: 0.9498\n",
      "Epoch 4: val_loss improved from 0.16895 to 0.16860, saving model to avg-word2vec-mort_icu-best_model.hdf5\n",
      "242/242 [==============================] - 11s 45ms/step - loss: 0.1572 - acc: 0.9499 - val_loss: 0.1686 - val_acc: 0.9462\n",
      "Epoch 5/100\n",
      "241/242 [============================>.] - ETA: 0s - loss: 0.1534 - acc: 0.9475\n",
      "Epoch 5: val_loss did not improve from 0.16860\n",
      "242/242 [==============================] - 12s 48ms/step - loss: 0.1534 - acc: 0.9475 - val_loss: 0.1707 - val_acc: 0.9444\n",
      "Epoch 6/100\n",
      "241/242 [============================>.] - ETA: 0s - loss: 0.1487 - acc: 0.9502\n",
      "Epoch 6: val_loss did not improve from 0.16860\n",
      "242/242 [==============================] - 11s 44ms/step - loss: 0.1486 - acc: 0.9503 - val_loss: 0.1720 - val_acc: 0.9439\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - ETA: 0s - loss: 0.1452 - acc: 0.9515\n",
      "Epoch 7: val_loss did not improve from 0.16860\n",
      "242/242 [==============================] - 13s 52ms/step - loss: 0.1452 - acc: 0.9515 - val_loss: 0.1704 - val_acc: 0.9466\n",
      "Epoch 8/100\n",
      "241/242 [============================>.] - ETA: 0s - loss: 0.1424 - acc: 0.9527\n",
      "Epoch 8: val_loss did not improve from 0.16860\n",
      "242/242 [==============================] - 14s 59ms/step - loss: 0.1427 - acc: 0.9525 - val_loss: 0.1709 - val_acc: 0.9444\n",
      "Epoch 9/100\n",
      "241/242 [============================>.] - ETA: 0s - loss: 0.1398 - acc: 0.9531\n",
      "Epoch 9: val_loss did not improve from 0.16860\n",
      "242/242 [==============================] - 12s 48ms/step - loss: 0.1401 - acc: 0.9531 - val_loss: 0.1708 - val_acc: 0.9439\n",
      "138/138 [==============================] - 2s 10ms/step\n",
      "0.8912473864113692 0.5335865243316403 0.9428636467106761 0.4434589800443459\n",
      "Embedding:  fasttext\n",
      "=============================\n",
      "Iteration number:  1\n",
      "Problem type:  mort_hosp\n",
      "__________________\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - ETA: 0s - loss: 0.2824 - acc: 0.9052\n",
      "Epoch 1: val_loss improved from inf to 0.24086, saving model to avg-fasttext-mort_hosp-best_model.hdf5\n",
      "242/242 [==============================] - 15s 53ms/step - loss: 0.2824 - acc: 0.9052 - val_loss: 0.2409 - val_acc: 0.9175\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - ETA: 0s - loss: 0.2383 - acc: 0.9179\n",
      "Epoch 2: val_loss improved from 0.24086 to 0.23523, saving model to avg-fasttext-mort_hosp-best_model.hdf5\n",
      "242/242 [==============================] - 12s 51ms/step - loss: 0.2383 - acc: 0.9179 - val_loss: 0.2352 - val_acc: 0.9152\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - ETA: 0s - loss: 0.2276 - acc: 0.9210\n",
      "Epoch 3: val_loss did not improve from 0.23523\n",
      "242/242 [==============================] - 11s 45ms/step - loss: 0.2276 - acc: 0.9210 - val_loss: 0.2364 - val_acc: 0.9120\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - ETA: 0s - loss: 0.2194 - acc: 0.9238\n",
      "Epoch 4: val_loss improved from 0.23523 to 0.23511, saving model to avg-fasttext-mort_hosp-best_model.hdf5\n",
      "242/242 [==============================] - 12s 51ms/step - loss: 0.2194 - acc: 0.9238 - val_loss: 0.2351 - val_acc: 0.9166\n",
      "Epoch 5/100\n",
      "241/242 [============================>.] - ETA: 0s - loss: 0.2153 - acc: 0.9243\n",
      "Epoch 5: val_loss did not improve from 0.23511\n",
      "242/242 [==============================] - 11s 47ms/step - loss: 0.2153 - acc: 0.9243 - val_loss: 0.2378 - val_acc: 0.9143\n",
      "Epoch 6/100\n",
      "241/242 [============================>.] - ETA: 0s - loss: 0.2106 - acc: 0.9255\n",
      "Epoch 6: val_loss improved from 0.23511 to 0.23397, saving model to avg-fasttext-mort_hosp-best_model.hdf5\n",
      "242/242 [==============================] - 10s 42ms/step - loss: 0.2108 - acc: 0.9254 - val_loss: 0.2340 - val_acc: 0.9166\n",
      "Epoch 7/100\n",
      "241/242 [============================>.] - ETA: 0s - loss: 0.2068 - acc: 0.9262\n",
      "Epoch 7: val_loss improved from 0.23397 to 0.23358, saving model to avg-fasttext-mort_hosp-best_model.hdf5\n",
      "242/242 [==============================] - 12s 49ms/step - loss: 0.2067 - acc: 0.9263 - val_loss: 0.2336 - val_acc: 0.9161\n",
      "Epoch 8/100\n",
      "241/242 [============================>.] - ETA: 0s - loss: 0.2040 - acc: 0.9268\n",
      "Epoch 8: val_loss did not improve from 0.23358\n",
      "242/242 [==============================] - 11s 46ms/step - loss: 0.2039 - acc: 0.9268 - val_loss: 0.2342 - val_acc: 0.9143\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - ETA: 0s - loss: 0.2014 - acc: 0.9278\n",
      "Epoch 9: val_loss did not improve from 0.23358\n",
      "242/242 [==============================] - 11s 45ms/step - loss: 0.2014 - acc: 0.9278 - val_loss: 0.2343 - val_acc: 0.9143\n",
      "Epoch 10/100\n",
      "241/242 [============================>.] - ETA: 0s - loss: 0.1995 - acc: 0.9280\n",
      "Epoch 10: val_loss did not improve from 0.23358\n",
      "242/242 [==============================] - 11s 44ms/step - loss: 0.1996 - acc: 0.9280 - val_loss: 0.2348 - val_acc: 0.9120\n",
      "Epoch 11/100\n",
      "241/242 [============================>.] - ETA: 0s - loss: 0.1977 - acc: 0.9289\n",
      "Epoch 11: val_loss did not improve from 0.23358\n",
      "242/242 [==============================] - 11s 44ms/step - loss: 0.1978 - acc: 0.9289 - val_loss: 0.2365 - val_acc: 0.9134\n",
      "Epoch 12/100\n",
      "241/242 [============================>.] - ETA: 0s - loss: 0.1958 - acc: 0.9293\n",
      "Epoch 12: val_loss did not improve from 0.23358\n",
      "242/242 [==============================] - 10s 43ms/step - loss: 0.1957 - acc: 0.9293 - val_loss: 0.2357 - val_acc: 0.9166\n",
      "138/138 [==============================] - 2s 9ms/step\n",
      "0.8820747963641171 0.5860902966273012 0.9189619849760984 0.4702380952380953\n",
      "Problem type:  mort_icu\n",
      "__________________\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - ETA: 0s - loss: 0.2108 - acc: 0.9374\n",
      "Epoch 1: val_loss improved from inf to 0.18053, saving model to avg-fasttext-mort_icu-best_model.hdf5\n",
      "242/242 [==============================] - 13s 45ms/step - loss: 0.2108 - acc: 0.9374 - val_loss: 0.1805 - val_acc: 0.9444\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - ETA: 0s - loss: 0.1766 - acc: 0.9435\n",
      "Epoch 2: val_loss improved from 0.18053 to 0.17418, saving model to avg-fasttext-mort_icu-best_model.hdf5\n",
      "242/242 [==============================] - 11s 44ms/step - loss: 0.1766 - acc: 0.9435 - val_loss: 0.1742 - val_acc: 0.9435\n",
      "Epoch 3/100\n",
      "241/242 [============================>.] - ETA: 0s - loss: 0.1645 - acc: 0.9474\n",
      "Epoch 3: val_loss improved from 0.17418 to 0.17402, saving model to avg-fasttext-mort_icu-best_model.hdf5\n",
      "242/242 [==============================] - 11s 44ms/step - loss: 0.1647 - acc: 0.9473 - val_loss: 0.1740 - val_acc: 0.9435\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - ETA: 0s - loss: 0.1586 - acc: 0.9492\n",
      "Epoch 4: val_loss improved from 0.17402 to 0.17142, saving model to avg-fasttext-mort_icu-best_model.hdf5\n",
      "242/242 [==============================] - 11s 44ms/step - loss: 0.1586 - acc: 0.9492 - val_loss: 0.1714 - val_acc: 0.9421\n",
      "Epoch 5/100\n",
      "241/242 [============================>.] - ETA: 0s - loss: 0.1540 - acc: 0.9499\n",
      "Epoch 5: val_loss did not improve from 0.17142\n",
      "242/242 [==============================] - 11s 44ms/step - loss: 0.1540 - acc: 0.9499 - val_loss: 0.1723 - val_acc: 0.9444\n",
      "Epoch 6/100\n",
      "241/242 [============================>.] - ETA: 0s - loss: 0.1508 - acc: 0.9514\n",
      "Epoch 6: val_loss did not improve from 0.17142\n",
      "242/242 [==============================] - 11s 44ms/step - loss: 0.1508 - acc: 0.9514 - val_loss: 0.1719 - val_acc: 0.9439\n",
      "Epoch 7/100\n",
      "241/242 [============================>.] - ETA: 0s - loss: 0.1466 - acc: 0.9509\n",
      "Epoch 7: val_loss did not improve from 0.17142\n",
      "242/242 [==============================] - 11s 44ms/step - loss: 0.1466 - acc: 0.9509 - val_loss: 0.1729 - val_acc: 0.9430\n",
      "Epoch 8/100\n",
      "241/242 [============================>.] - ETA: 0s - loss: 0.1442 - acc: 0.9518\n",
      "Epoch 8: val_loss did not improve from 0.17142\n",
      "242/242 [==============================] - 11s 44ms/step - loss: 0.1441 - acc: 0.9518 - val_loss: 0.1718 - val_acc: 0.9425\n",
      "Epoch 9/100\n",
      "241/242 [============================>.] - ETA: 0s - loss: 0.1416 - acc: 0.9529\n",
      "Epoch 9: val_loss did not improve from 0.17142\n",
      "242/242 [==============================] - 10s 43ms/step - loss: 0.1417 - acc: 0.9529 - val_loss: 0.1729 - val_acc: 0.9439\n",
      "138/138 [==============================] - 2s 9ms/step\n",
      "0.8896725967867108 0.5342498504497342 0.943546551331664 0.4632034632034632\n"
     ]
    }
   ],
   "source": [
    "embedding_types = ['word2vec', 'fasttext'] #, 'concat']\n",
    "embedding_dict = [ner_word2vec, ner_fasttext] #, ner_concat]\n",
    "target_problems = ['mort_hosp', 'mort_icu'] #, 'los_3', 'los_7']\n",
    "\n",
    "\n",
    "num_epoch = 100\n",
    "model_patience = 5\n",
    "monitor_criteria = 'val_loss'\n",
    "batch_size = 64\n",
    "iter_num = 2\n",
    "unit_sizes = [128, 256]\n",
    "\n",
    "#layers = [\"LSTM\", \"GRU\"]\n",
    "layers = [\"GRU\"]\n",
    "for each_layer in layers:\n",
    "    print (\"Layer: \", each_layer)\n",
    "    for each_unit_size in unit_sizes:\n",
    "        print (\"Hidden unit: \", each_unit_size)\n",
    "\n",
    "        for embed_dict, embed_name in zip(embedding_dict, embedding_types):    \n",
    "            print (\"Embedding: \", embed_name)\n",
    "            print(\"=============================\")\n",
    "\n",
    "            temp_train_ner = dict((k, ner_word2vec[k]) for k in train_ids)\n",
    "            temp_dev_ner = dict((k, ner_word2vec[k]) for k in dev_ids)\n",
    "            temp_test_ner = dict((k, ner_word2vec[k]) for k in test_ids)\n",
    "\n",
    "            x_train_ner = create_dataset(temp_train_ner)\n",
    "            x_dev_ner = create_dataset(temp_dev_ner)\n",
    "            x_test_ner = create_dataset(temp_test_ner)\n",
    "\n",
    "\n",
    "            for iteration in range(1, iter_num):\n",
    "                print (\"Iteration number: \", iteration)\n",
    "\n",
    "                for each_problem in target_problems:\n",
    "                    print (\"Problem type: \", each_problem)\n",
    "                    print (\"__________________\")\n",
    "\n",
    "                    early_stopping_monitor = EarlyStopping(monitor=monitor_criteria, patience=model_patience)\n",
    "                    best_model_name = \"avg-\"+str(embed_name)+\"-\"+str(each_problem)+\"-\"+\"best_model.hdf5\"\n",
    "                    checkpoint = ModelCheckpoint(best_model_name, monitor='val_loss', verbose=1,\n",
    "                        save_best_only=True, mode='min', period=1)\n",
    "\n",
    "\n",
    "                    callbacks = [early_stopping_monitor, checkpoint]\n",
    "\n",
    "                    model = avg_ner_model(each_layer, each_unit_size, embed_name)\n",
    "                    \n",
    "                    model.fit([x_train_lstm, x_train_ner], y_train[each_problem], epochs=num_epoch, verbose=1, \n",
    "                              validation_data=([x_dev_lstm, x_dev_ner], y_dev[each_problem]), callbacks=callbacks, \n",
    "                              batch_size=batch_size )\n",
    "\n",
    "                    model.load_weights(best_model_name)\n",
    "\n",
    "                    probs, predictions = make_prediction_multi_avg(model, [x_test_lstm, x_test_ner])\n",
    "                    \n",
    "                    save_scores_multi_avg(predictions, probs, y_test[each_problem],\n",
    "                                embed_name, each_problem, iteration, each_unit_size,\n",
    "                                each_layer, type_of_ner)\n",
    "\n",
    "\n",
    "                    # reset_keras(model)\n",
    "                    #del model\n",
    "                    sess = get_session()\n",
    "                    clear_session()\n",
    "                    sess.close()\n",
    "                    gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
