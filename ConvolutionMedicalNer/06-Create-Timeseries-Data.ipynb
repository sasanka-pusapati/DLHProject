{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lvl2_train =  pd.read_pickle(\"data/lvl2_imputer_train_\"+str(SEED)+\".pkl\")\n",
    "# lvl2_dev =  pd.read_pickle(\"data/lvl2_imputer_dev_\"+str(SEED)+\".pkl\")\n",
    "# lvl2_test =  pd.read_pickle(\"data/lvl2_imputer_test_\"+str(SEED)+\".pkl\")\n",
    "#\n",
    "# Ys =  pd.read_pickle(\"data/Ys_\"+str(SEED)+\".pkl\")\n",
    "# Ys_train =  pd.read_pickle(\"data/Ys_train_\"+str(SEED)+\".pkl\")\n",
    "# Ys_dev =  pd.read_pickle(\"data/Ys_dev_\"+str(SEED)+\".pkl\")\n",
    "# Ys_test =  pd.read_pickle(\"data/Ys_test_\"+str(SEED)+\".pkl\")\n",
    "\n",
    "#[sasanka2@illinois.edu] Updated the file names for reading\n",
    "lvl2_train =  pd.read_pickle(\"data/lvl2_imputer_train.pkl\")\n",
    "lvl2_dev =  pd.read_pickle(\"data/lvl2_imputer_dev.pkl\")\n",
    "lvl2_test =  pd.read_pickle(\"data/lvl2_imputer_test.pkl\")\n",
    "Ys = pd.read_pickle(\"data/Ys.pkl\")\n",
    "Ys_train =  pd.read_pickle(\"data/Ys_train.pkl\")\n",
    "Ys_dev =  pd.read_pickle(\"data/Ys_dev.pkl\")\n",
    "Ys_test =  pd.read_pickle(\"data/Ys_test.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_train_ids = set()\n",
    "for i in Ys_train.itertuples():\n",
    "    all_train_ids.add( i.Index[0] )\n",
    "    \n",
    "all_dev_ids = set()\n",
    "for i in Ys_dev.itertuples():\n",
    "    all_dev_ids.add( i.Index[0] )\n",
    "    \n",
    "all_test_ids = set()\n",
    "for i in Ys_test.itertuples():\n",
    "    all_test_ids.add( i.Index[0] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.07159904534606205\n",
      "0.06725146198830409\n",
      "0.07432150313152401\n",
      "====\n",
      "0.10680190930787589\n",
      "0.09649122807017543\n",
      "0.10855949895615867\n",
      "====\n",
      "0.43323389021479713\n",
      "0.42105263157894735\n",
      "0.4246346555323591\n",
      "====\n",
      "0.07696897374701671\n",
      "0.07268170426065163\n",
      "0.07954070981210856\n"
     ]
    }
   ],
   "source": [
    "print (sum(Ys_train.mort_icu.values)*1.0 / len(Ys_train.mort_icu.values))\n",
    "print (sum(Ys_dev.mort_icu.values)*1.0 / len(Ys_dev.mort_icu.values))\n",
    "print (sum(Ys_test.mort_icu.values)*1.0 / len(Ys_test.mort_icu.values))\n",
    "print (\"====\")\n",
    "print (sum(Ys_train.mort_hosp.values)*1.0 / len(Ys_train.mort_hosp.values))\n",
    "print (sum(Ys_dev.mort_hosp.values)*1.0 / len(Ys_dev.mort_hosp.values))\n",
    "print (sum(Ys_test.mort_hosp.values)*1.0 / len(Ys_test.mort_hosp.values))\n",
    "print (\"====\")\n",
    "print (sum(Ys_train.los_3.values)*1.0 / len(Ys_train.los_3.values))\n",
    "print (sum(Ys_dev.los_3.values)*1.0 / len(Ys_dev.los_3.values))\n",
    "print (sum(Ys_test.los_3.values)*1.0 / len(Ys_test.los_3.values))\n",
    "print (\"====\")\n",
    "print (sum(Ys_train.los_7.values)*1.0 / len(Ys_train.los_7.values))\n",
    "print (sum(Ys_dev.los_7.values)*1.0 / len(Ys_dev.los_7.values))\n",
    "print (sum(Ys_test.los_7.values)*1.0 / len(Ys_test.los_7.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_word2vec_dict = pd.read_pickle(\"data/new_ner_word2vec_dict.pkl\")\n",
    "new_keys = set(new_word2vec_dict.keys())\n",
    "new_train_ids = sorted(all_train_ids.intersection(new_keys))\n",
    "new_dev_ids = sorted(all_dev_ids.intersection(new_keys))\n",
    "new_test_ids = sorted(all_test_ids.intersection(new_keys))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_train_ids = pd.to_pickle(new_train_ids,\"data/new_train_ids.pkl\")\n",
    "new_dev_ids = pd.to_pickle(new_dev_ids,\"data/new_dev_ids.pkl\")\n",
    "new_test_ids = pd.to_pickle(new_test_ids,\"data/new_test_ids.pkl\")\n",
    "\n",
    "new_train_ids = pd.read_pickle(\"data/new_train_ids.pkl\")\n",
    "new_dev_ids = pd.read_pickle(\"data/new_dev_ids.pkl\")\n",
    "new_test_ids = pd.read_pickle(\"data/new_test_ids.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_ids = [(new_train_ids, new_dev_ids, new_test_ids)]\n",
    "data_names = [\"new\"]\n",
    "\n",
    "for i, (tr, de, te) in zip(data_names, data_ids):\n",
    "    \n",
    "    y_train = Ys_train.loc[tr]\n",
    "    y_dev = Ys_dev.loc[de]\n",
    "    y_test = Ys_test.loc[te]\n",
    "\n",
    "    sub_train = lvl2_train.loc[tr]\n",
    "    sub_train = sub_train.loc[:, pd.IndexSlice[:, 'mean']]\n",
    "\n",
    "    sub_dev = lvl2_dev.loc[de]\n",
    "    sub_dev = sub_dev.loc[:, pd.IndexSlice[:, 'mean']]\n",
    "\n",
    "    sub_test = lvl2_test.loc[te]\n",
    "    sub_test = sub_test.loc[:, pd.IndexSlice[:, 'mean']]\n",
    "\n",
    "    #sub_train = sub_train.as_matrix()\n",
    "    #sub_dev = sub_dev.as_matrix()\n",
    "    #sub_test = sub_test.as_matrix()\n",
    "    #[sasanka2@illinois.edu] Replaced deprecated matric api with to_numpy\n",
    "    sub_train = sub_train.to_numpy()\n",
    "    sub_dev = sub_dev.to_numpy()\n",
    "    sub_test = sub_test.to_numpy()\n",
    "\n",
    "    # reshape the data for timeseries prediction\n",
    "    x_train_lstm = sub_train.reshape(int(sub_train.shape[0] / 24), 24, 104)\n",
    "    x_dev_lstm = sub_dev.reshape(int(sub_dev.shape[0] / 24), 24, 104)\n",
    "    x_test_lstm = sub_test.reshape(int(sub_test.shape[0] / 24), 24, 104)\n",
    "\n",
    "    \n",
    "    pd.to_pickle(x_train_lstm, \"data/\"+i+\"_x_train.pkl\")\n",
    "    pd.to_pickle(x_dev_lstm, \"data/\"+i+\"_x_dev.pkl\")\n",
    "    pd.to_pickle(x_test_lstm, \"data/\"+i+\"_x_test.pkl\")\n",
    "    \n",
    "    pd.to_pickle(y_train, \"data/\"+i+\"_y_train.pkl\")\n",
    "    pd.to_pickle(y_dev, \"data/\"+i+\"_y_dev.pkl\")\n",
    "    pd.to_pickle(y_test, \"data/\"+i+\"_y_test.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
